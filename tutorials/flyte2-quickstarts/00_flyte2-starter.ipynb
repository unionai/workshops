{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae779f5",
   "metadata": {},
   "source": [
    "# Intro to Flyte 2 - Scaleable Dynamic Workflows for ML Pipelines and AI Agents\n",
    "\n",
    "To run this tutorial you'll need to be either an exsisting Union.ai user with Flyte v2, or [sign up for the free Beta access](https://www.union.ai/beta)!\n",
    "\n",
    "[Flyte 2.0](https://github.com/flyteorg/flyte-sdk) is an orchestration platform for building and managing highly scalable, dynamic, and distributed workflows. \n",
    "\n",
    "Examples in this notebook:\n",
    "- Setup (Do this first before running anyt of the examples)\n",
    "- Hello Flyte tasks\n",
    "- ML pipeline - custom environments, caching, reporting, Flyte Files\n",
    "- Error handling and dynamic infra\n",
    "- AI Agents with Flyte - coming soon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594d4eb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "if you're running this notebook locally we suggest creating a virtual environment and installing the packages locally with uv. You can follow the [instructions on the README](README.md).\n",
    "```|\n",
    "uv venv .venv --python=python3.11\n",
    "source .venv/bin/activate\n",
    "uv pip install 'flyte>=2.0.0b21' --prerelease=allow\n",
    "```\n",
    "If you're running this in google colab run the two setup cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!uv pip install 'flyte>=2.0.0b21' --prerelease=allow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cabef4a",
   "metadata": {},
   "source": [
    "##### Flyte Config\n",
    "if you're running this notebook locally you can remove `--auth-type headless\\`\n",
    "\n",
    "If you have an existing config you can skip this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flyte create config \\\n",
    "    --endpoint tryv2.hosted.unionai.cloud \\\n",
    "    --auth-type headless\\\n",
    "    --builder remote \\\n",
    "    --domain development \\\n",
    "    --project flytesnacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d56d7",
   "metadata": {},
   "source": [
    "## ðŸ‘‹ Hello Flyte Tasks\n",
    "\n",
    "TaskEnvironment: A TaskEnvironment object is the abstraction that defines the hardware and software environment in which one or more tasks are executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flyte\n",
    "\n",
    "# Create a task environment with resource specifications\n",
    "env = flyte.TaskEnvironment(\n",
    "    name=\"hello_flyte_simple\",\n",
    "    resources=flyte.Resources(cpu=1, memory=\"250Mi\"),\n",
    ")\n",
    "\n",
    "\n",
    "@env.task # Decorator to define a Flyte task (a unit of work in a environment)\n",
    "def process_and_validate(user_input: str) -> dict:\n",
    "    \"\"\"Extract features and validate in a single task\"\"\"\n",
    "    clean = user_input.strip().lower()\n",
    "    \n",
    "    features = {\n",
    "        \"text\": clean,\n",
    "        \"length\": len(clean),\n",
    "        \"word_count\": len(clean.split()),\n",
    "        \"has_numbers\": any(c.isdigit() for c in clean),\n",
    "        \"is_valid\": len(clean) > 5 and len(clean.split()) >= 2  # validation criteria\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# tasks can be called in within other tasks to create workflows\n",
    "@env.task \n",
    "def analyze_batch_workflow(raw_inputs: list[str]) -> dict:\n",
    "    \"\"\"Process all inputs and generate summary statistics\"\"\"\n",
    "    if len(raw_inputs) < 3:\n",
    "        raise ValueError(f\"Need at least 3 samples, got: {len(raw_inputs)}\")\n",
    "\n",
    "    # Use Flyte's map function to process all inputs in parallel\n",
    "    all_features = list(flyte.map(process_and_validate, raw_inputs))\n",
    "    \n",
    "    valid_samples = [f for f in all_features if f[\"is_valid\"]]\n",
    "\n",
    "    summary = {\n",
    "        \"total_samples\": len(all_features),\n",
    "        \"valid_samples\": len(valid_samples),\n",
    "        \"avg_length\": sum(f[\"length\"] for f in all_features) / len(all_features),\n",
    "        \"ready_for_training\": len(valid_samples) >= len(all_features) * 0.7\n",
    "    }\n",
    "\n",
    "    print(\"Processed features:\", summary)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Sample data to analyze\n",
    "sample_reviews = [\n",
    "    \"  This product is amazing! I love it.  \",\n",
    "    \"Great quality and fast shipping\", \n",
    "    \" Bad \",  # Will be invalid (too short)\n",
    "    \"The delivery was delayed by 3 days\",\n",
    "    \"Excellent customer service team\",\n",
    "    \"Perfect for my home office setup\"\n",
    "]\n",
    "\n",
    "# Initialize Flyte and run the workflow\n",
    "flyte.init_from_config(\".flyte/config.yaml\")\n",
    "execution = flyte.run(analyze_batch_workflow, raw_inputs=sample_reviews)\n",
    "\n",
    "print(f\"Execution: {execution.name}\")\n",
    "print(f\"URL: {execution.url}\")\n",
    "print(\"Click the link above to view execution details in the Flyte UI ðŸ‘†\")\n",
    "# Click the signin link to run your Flyte workflow!ðŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd8f3d",
   "metadata": {},
   "source": [
    "#### Run tasks locally\n",
    "Running tasks locally is a great way to debug and iterate quickly without needing to run on a remote cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flyte.init() #overwrite flyte init from config\n",
    "execution = flyte.run(analyze_batch_workflow, raw_inputs=sample_reviews)\n",
    "print(f\"Execution: {execution.name}\")\n",
    "print(f\"URL: {execution.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868922e",
   "metadata": {},
   "source": [
    "This was a quick example of running a flyte 2.0 task. The next section will show you how to run a full workflow with multiple tasks and dependencies.\n",
    "\n",
    "Check out the [Flyte 2.0 documentation](https://www.union.ai/docs/v2/flyte/user-guide/) for more examples and details on how to use Flyte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115368d7",
   "metadata": {},
   "source": [
    "## Build an ML Pipeline (and see more features)\n",
    "\n",
    "Let's build a simple ML pipeline using sklearn and the iris dataset. We'll use some more advanced features of Flyte like:\n",
    "\n",
    "- Build custom environments (containers) -> read more in the [docs]() \n",
    "- Reusable environments (containers)\n",
    "- Caching (to speed up workflows)\n",
    "- Reporting (to visualize results in the UI)\n",
    "- Flyte Files (to manage data and model artifacts)\n",
    "\n",
    "This pipeline can be extended to more complex use cases, but this should give you a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd99749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import io\n",
    "from textwrap import dedent\n",
    "from typing import List\n",
    "import joblib\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\") # Use a non-interactive backend for matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import base64\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import flyte.report\n",
    "import flyte\n",
    "from flyte.io import Dir, File\n",
    "\n",
    "# Custom environment with scikit-learn installed\n",
    "env = flyte.TaskEnvironment(\n",
    "    name=\"scikit_learn_pipeline\",\n",
    "    resources=flyte.Resources(cpu=2, memory=\"2Gi\"),\n",
    "    reusable=flyte.ReusePolicy(\n",
    "        replicas=3,\n",
    "        idle_ttl=120,\n",
    "        concurrency=6,\n",
    "        scaledown_ttl=120,\n",
    "    ),\n",
    "    image=flyte.Image.from_debian_base().with_pip_packages(\"scikit-learn\", \"pandas\",\n",
    "                                                           \"unionai-reuse==0.1.6\", \"joblib==1.3.2\",\n",
    "                                                           \"matplotlib==3.8.3\", \"seaborn==0.13.2\",\n",
    "                                                           \"pyarrow\", \"fastparquet\"),\n",
    ")\n",
    "\n",
    "# Helper function to convert a matplotlib figure into an HTML string\n",
    "def _convert_fig_into_html(fig: mpl.figure.Figure) -> str:\n",
    "    img_buf = io.BytesIO()\n",
    "    fig.savefig(img_buf, format=\"png\")\n",
    "    img_base64 = base64.b64encode(img_buf.getvalue()).decode()\n",
    "    return f'<img src=\"data:image/png;base64,{img_base64}\" alt=\"Rendered Image\" />'\n",
    "\n",
    "@env.task(cache=\"auto\")\n",
    "async def download_dataset() -> pd.DataFrame:\n",
    "    iris = load_iris()\n",
    "    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "    iris_df['target'] = iris.target\n",
    "    return iris_df\n",
    "\n",
    "@env.task(report=True, cache=\"auto\")\n",
    "async def process_dataset(data_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    # Perform the train-test split\n",
    "    train_df, test_df = train_test_split(data_df,\n",
    "                                         test_size=0.2,\n",
    "                                         random_state=42,\n",
    "                                         stratify=data_df['target'])\n",
    "\n",
    "    # Seaborn pairplot full dataset\n",
    "    pairplot = sns.pairplot(data_df, hue=\"target\")\n",
    "\n",
    "    html_content = _convert_fig_into_html(pairplot.figure)\n",
    "    plt.close(pairplot.figure)\n",
    "\n",
    "    await flyte.report.replace.aio(html_content) # Report to Flyte UI\n",
    "    await flyte.report.flush.aio() # Ensure report is sent\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "@env.task\n",
    "async def train_model(dataset: pd.DataFrame, n_neighbors: int = 3) -> File:\n",
    "    X_train, y_train = dataset.drop(\"target\", axis=\"columns\"), dataset[\"target\"]\n",
    "    model = knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    trained_model = model.fit(X_train, y_train)\n",
    "    out_path = \"trained_model.joblib\" # Local path to save the model\n",
    "    joblib.dump(model, out_path) # Save the trained model locally\n",
    "\n",
    "    return await File.from_local(out_path) # Return an uploaded Flyte File reference\n",
    "\n",
    "\n",
    "@env.task(report=True)\n",
    "async def evaluate_model(model_file: File, dataset: pd.DataFrame) -> set[str]:\n",
    "    local_path = await model_file.download()\n",
    "    model: KNeighborsClassifier = joblib.load(local_path)\n",
    "\n",
    "    X_test, y_test = dataset.drop(columns=[\"target\"]), dataset[\"target\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax)\n",
    "    html_cm = _convert_fig_into_html(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Text report\n",
    "    report_txt = classification_report(y_test, y_pred)\n",
    "    print(dedent(f\"\"\"\n",
    "    Classification Report\n",
    "    ---------------------\n",
    "    {report_txt}\n",
    "    \"\"\"))\n",
    "    html_report = f\"<pre>{report_txt}</pre>\"\n",
    "\n",
    "    await flyte.report.replace.aio(\"<h3>Confusion Matrix</h3>\" + html_cm + \"<h3>Classification Report</h3>\" + html_report)\n",
    "    await flyte.report.flush.aio()\n",
    "\n",
    "    return {report_txt}\n",
    "\n",
    "\n",
    "@env.task\n",
    "async def model_predict(model_file: File, pred_data: List[List[float]]) -> List[int]:\n",
    "    local_path = await model_file.download()\n",
    "    model: KNeighborsClassifier = joblib.load(local_path)\n",
    "    predictions = model.predict(pred_data)\n",
    "    return predictions.tolist()\n",
    "\n",
    "\n",
    "@env.task\n",
    "async def ml_pipeline(n_neighbors: int = 3,\n",
    "    pred_data: List[List[float]] = [[1.5, 2.3, 1.3, 2.4]]) -> File:\n",
    "    data_df = await download_dataset()\n",
    "    train, test = await process_dataset(data_df)\n",
    "    model = await train_model(dataset=train, n_neighbors=n_neighbors)\n",
    "    class_report = await evaluate_model(model_file=model, dataset=test)\n",
    "    (print(f\"Classification Report: {class_report}\"))\n",
    "    pred = await model_predict(model_file=model, pred_data=pred_data)\n",
    "    (print(f\"Predictions for {pred_data}: {pred}\"))\n",
    "    return model\n",
    "\n",
    "# Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    flyte.init_from_config(\".flyte/config.yaml\")\n",
    "    # flyte.init() # uncomment to run locally\n",
    "\n",
    "    # Run the complete pipeline\n",
    "    execution = flyte.run(ml_pipeline)\n",
    "\n",
    "    print(f\"Execution: {execution.name}\")\n",
    "    print(f\"URL: {execution.url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b0d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ea609fe",
   "metadata": {},
   "source": [
    "#### Outputs & Flyte Remote\n",
    "\n",
    "Note: if you're on the `tryv2` demo cluster, you will not be able to download stored artifacts directly. But if you're on a full deployment or have access to your own cluster you can download the artifacts by passing in your storage authorization credentials. \n",
    "\n",
    "You can however move artifacts from `tryv2` within a workflow, such as sending to Hugging Face for storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example coming soon to the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331bc11",
   "metadata": {},
   "source": [
    "## âš ï¸ Error Handling & Dynamic Infrastructure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5647df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import flyte\n",
    "import flyte.errors\n",
    "\n",
    "env = flyte.TaskEnvironment(\n",
    "    name=\"fail\",\n",
    "    resources=flyte.Resources(cpu=1, memory=\"250Mi\"),\n",
    ")\n",
    "\n",
    "\n",
    "@env.task\n",
    "async def oomer(x: int):\n",
    "    large_list = [0] * 100000000\n",
    "    print(len(large_list))\n",
    "\n",
    "\n",
    "@env.task\n",
    "async def always_succeeds() -> int:\n",
    "    await asyncio.sleep(1)\n",
    "    return 42\n",
    "\n",
    "\n",
    "@env.task\n",
    "async def failure_recovery() -> int:\n",
    "    try:\n",
    "        await oomer(2)\n",
    "    except flyte.errors.OOMError as e:\n",
    "        print(f\"Failed with oom trying with more resources: {e}, of type {type(e)}, {e.code}\")\n",
    "        try:\n",
    "            await oomer.override(resources=flyte.Resources(cpu=1, memory=\"1Gi\"))(5)\n",
    "        except flyte.errors.OOMError as e:\n",
    "            print(f\"Failed with OOM Again giving up: {e}, of type {type(e)}, {e.code}\")\n",
    "            raise e\n",
    "    finally:\n",
    "        await always_succeeds()\n",
    "\n",
    "    return await always_succeeds()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flyte.init_from_config(\".flyte/config.yaml\")\n",
    "\n",
    "    run = flyte.run(failure_recovery)\n",
    "    print(run.url)\n",
    "    run.wait(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263385b",
   "metadata": {},
   "source": [
    "## AI Agents & Agentic Workflows\n",
    "\n",
    "Flyte 2.0 built in dynamic task and workflows make it easy to build agentic workflows that can call LLMs and other AI models to help make decisions and take actions with out of the box support for most major agent frameworks and LLM providers.\n",
    "\n",
    "`Example Coming soon!`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df69ac",
   "metadata": {},
   "source": [
    "## Create and Manage Secrets\n",
    "`Example Coming soon!`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd5523b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
